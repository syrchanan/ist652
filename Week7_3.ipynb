{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "#Webpage that will be scraped\n",
    "myurl = 'https://www.cnbc.com/2020/02/14/stanford-scientist-on-proven-habits-that-will-make-you-more-productive.html'\n",
    "\n",
    "response = request.urlopen(myurl)\n",
    "# After issuing our request, we get a Response object. This object has a status_code property,\n",
    "# which indicates if the page was downloaded successfully:\n",
    "# A status_code of 200 means that the page downloaded successfully. A status code starting with a 2\n",
    "# generally indicates success, and a code starting with a 4 or a 5 indicates an error.\n",
    "status = response.code\n",
    "print('status:', status, '\\n')\n",
    "if status != 200:\n",
    "    print('Bad Status')\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# The response object contains a webpage representation that needs to be decoded and converted to a Python string.\n",
    "try:\n",
    "    html = response.read().decode('utf8')\n",
    "except ConnectionResetError:\n",
    "    print('Connection Reset Error')\n",
    "    quit()\n",
    "except Exception as ex:\n",
    "    template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "    message = template.format(type(ex).__name__, ex.args)\n",
    "    print(message)\n",
    "    quit()\n",
    "\n",
    "print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the BeautifulSoup library to parse the HTML document, and extract the text\n",
    "# from the p tag. We first have to import the library, and create an instance of\n",
    "# the BeautifulSoup class to parse our document:\n",
    "import bs4\n",
    "soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# We can now print out the HTML content of the page, formatted nicely, using the\n",
    "# prettify method on the BeautifulSoup object:\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags = (soup.find_all('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags   #I need to target the p tags that have the content I'm looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags = (soup.find_all('p'))\n",
    "for i in range(16,28):\n",
    "    print(p_tags[i].get_text())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
